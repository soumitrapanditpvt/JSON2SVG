name: SVG Conversion Workflow with Pre-Built Docker Image

on:
  push:
    branches:
      - main
    paths:
      - '**/*.json'  # Trigger the workflow for any .json file change in any directory

  pull_request:
    branches:
      - main
    paths:
      - '**/*.json'

  workflow_dispatch:

jobs:
  build-and-convert:
    runs-on: ubuntu-latest

    # Use the pre-built Docker image from GitHub Container Registry
    container:
      image: ghcr.io/primevisiontechnology-com/pvt-converter-gh-buildimage-python-3.12:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GHCR_PAT }}  # Use the PAT stored in the repository secrets

    steps:
      # Step 1: Check out the repository code
      - name: Checkout repository
        uses: actions/checkout@v2

      # Step 2: Mark the repository as a safe directory for Git
      - name: Mark repository as safe for Git
        run: git config --global --add safe.directory $GITHUB_WORKSPACE

      # Step 3: Get list of modified JSON files using git log and format them correctly
      - name: Get modified JSON files
        id: get_files
        run: |
          # Capture the modified JSON files using git log
          MODIFIED_JSON_FILES=$(git log -m -1 --name-only --pretty="" -- '*.json')

          # Debugging: Print the exact list of modified files
          echo "Raw MODIFIED_JSON_FILES: $MODIFIED_JSON_FILES"

          # Replace newlines with a single space to create a properly formatted string
          FORMATTED_JSON_FILES=$(echo "$MODIFIED_JSON_FILES" | tr '\n' ' ')

          # Debugging: Print the formatted JSON files
          echo "Formatted MODIFIED_JSON_FILES: $FORMATTED_JSON_FILES"

          # Write the formatted JSON files to the GITHUB_ENV environment file
          echo "json_files=$FORMATTED_JSON_FILES" >> $GITHUB_ENV

      # Step 4: Extract directories from the modified JSON files and store them in GITHUB_ENV
      - name: Get modified directories
        id: get_dirs
        run: |
          # Access the json_files environment variable
          MODIFIED_JSON_FILES="${{ env.json_files }}"

          # Initialize an empty string to store modified folders
          MODIFIED_FOLDERS=""

          # Loop through each modified file and extract its directory
          for file in $MODIFIED_JSON_FILES; do
            folder=$(dirname "$file")
            echo "Found folder: $folder"  # Debugging: Print each folder found
            MODIFIED_FOLDERS="$MODIFIED_FOLDERS $folder"
          done

          # Print intermediate value of MODIFIED_FOLDERS for debugging
          echo "Intermediate MODIFIED_FOLDERS value: $MODIFIED_FOLDERS"

          # Use tr to convert spaces to newlines, sort uniquely, and remove empty lines
          MODIFIED_FOLDERS=$(echo "$MODIFIED_FOLDERS" | tr ' ' '\n' | sort -u | sed '/^$/d')

          # Format the variable correctly to avoid newlines or special characters
          FORMATTED_FOLDERS=$(printf "%s" "$MODIFIED_FOLDERS" | tr '\n' ' ' | sed 's/[[:space:]]*$//')

          # Debugging: Print the formatted folders for verification
          echo "Formatted directories: '$FORMATTED_FOLDERS'"

          # Write only the formatted directories to the GITHUB_ENV environment file
          echo "folders=$FORMATTED_FOLDERS" >> $GITHUB_ENV

      # Step 5: Install Azure CLI for uploading files to Azure Storage (without sudo)
      - name: "Install Az CLI"
        run: |
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
      - name: "Az CLI login"
        uses: azure/login@v1
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      # Step 6: Check and Create 'converted-floorplans' Directory in Azure
      - name: Check and Create 'converted-floorplans' Directory in Azure
        run: |
          if ! az storage blob list --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }} \
                                    --account-key ${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }} \
                                    --container-name floorplan-resources \
                                    --prefix "floorplans/converted-floorplans/" | grep -q "converted-floorplans"; then
            echo "'converted-floorplans' directory not found. Creating it..."
            echo "Creating placeholder blob to represent 'converted-floorplans' directory..."
            echo "placeholder" > placeholder.txt
            az storage blob upload --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }} \
                                   --account-key ${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }} \
                                   --container-name floorplan-resources \
                                   --file placeholder.txt \
                                   --name "floorplans/converted-floorplans/placeholder.txt"
            rm placeholder.txt
          fi

      # Step 7: Upload SVG files to Azure Storage using correct path structure
      - name: Upload SVGs to Azure Storage
        if: ${{ env.folders }}  # Corrected condition to check if env.folders is not empty
        run: |
          for folder in ${{ env.folders }}; do
            echo "Uploading contents of folder: $folder to Azure Storage"
            FULL_PATH=$(realpath /usr/src/app/$folder)
            FOLDER_NAME=$(basename $folder)
            az storage blob upload-batch --account-name ${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }} \
                                         --account-key ${{ secrets.AZURE_STORAGE_ACCOUNT_KEY }} \
                                         --destination floorplan-resources/floorplans/converted-floorplans/$FOLDER_NAME \
                                         --source "$FULL_PATH" \
                                         --pattern "**/*"
          done
